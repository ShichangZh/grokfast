{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def multiplication_mod_p_data(p, eq_token, op_token):\n",
    "    \"\"\"x◦y = x/y (mod p) for 0 ≤ x < p, 0 < y < p\n",
    "    \"\"\"\n",
    "    x = torch.arange(p)\n",
    "    y = torch.arange(1, p)\n",
    "    x, y = torch.cartesian_prod(x, y).T\n",
    "\n",
    "    eq = torch.ones_like(x) * eq_token\n",
    "    op = torch.ones_like(x) * op_token\n",
    "    result = x * y % p\n",
    "\n",
    "    # \"All of our experiments used a small transformer trained on datasets of\n",
    "    # equations of the form a◦b = c, where each of “a”, “◦”, “b”, “=”, and “c”\n",
    "    # is a seperate token\"\n",
    "    return torch.stack([x, op, y, eq, result])\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--p\", type=int, default=97)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "eq_token = args.p\n",
    "op_token = args.p + 1\n",
    "\n",
    "data = multiplication_mod_p_data(args.p, eq_token, op_token)\n",
    "\n",
    "train_idx, valid_idx = torch.randperm(data.shape[1]).split(data.shape[1] // 2)\n",
    "train_data, valid_data = data[:, train_idx], data[:, valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train, dataset_test = create_mnist_dataset(\"./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import numpy as np\n",
    "\n",
    "class ColumnDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.num_columns = data.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_columns\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[:, index]\n",
    "    \n",
    "# Custom sampler that samples per column\n",
    "class ColumnSampler(Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Return an iterator over the columns (indices 0 to number of columns - 1)\n",
    "        return iter(range(len(self.data_source)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "# Dataset where each column is a data point\n",
    "class ColumnDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.num_columns = data.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_columns\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[:, index]\n",
    "\n",
    "# Custom sampler that samples columns\n",
    "class ColumnSampler(Sampler):\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.num_columns = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = torch.randperm(self.num_columns).tolist()\n",
    "        # Yield indices in batches\n",
    "        for i in range(0, self.num_columns, self.batch_size):\n",
    "            yield indices[i:i + self.batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_columns + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "# Modified custom collate function to collapse the second dimension\n",
    "def custom_collate_fn(batch):\n",
    "    batch = torch.stack(batch, dim=1)  # Stack along dimension 1\n",
    "    return batch.squeeze(1)  # Remove the singleton dimension\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example data with shape (5, 4656)\n",
    "    data = torch.randn(5, 4656)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4656])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithmic data\n",
    "# dataset_train = train_data.T\n",
    "# dataset_test = valid_data.T\n",
    "\n",
    "dataset_train = ColumnDataset(train_data)\n",
    "dataset_test = ColumnDataset(valid_data)\n",
    "\n",
    "batch_size = 32  # Adjust as needed\n",
    "    \n",
    "# Create the custom ColumnSampler\n",
    "sampler_train = ColumnSampler(dataset_train, batch_size=batch_size)\n",
    "sampler_test = ColumnSampler(dataset_test, batch_size=batch_size)\n",
    "    \n",
    "# Create a DataLoader with the custom sampler and custom collate function\n",
    "train_loader = DataLoader(dataset_train, sampler=sampler_train, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(dataset_test, sampler=sampler_test, collate_fn=custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import Decoder\n",
    "# device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = Decoder(\n",
    "    dim=128, num_layers=2, num_heads=4, num_tokens=args.p + 2, seq_len=5\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "results = torch.load('results/res_test_none.pt')\n",
    "# results = torch.load('results/res_test_ma_w100_l5_wd10e-02.pt')\n",
    "# results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = results['net']\n",
    "model.load_state_dict(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_influence import BaseObjective\n",
    "\n",
    "class MyObjective(BaseObjective):\n",
    "\n",
    "    def train_outputs(self, model, batch):\n",
    "        return model(batch[0])\n",
    "\n",
    "    def train_loss_on_outputs(self, outputs, batch):\n",
    "        return F.cross_entropy(outputs, batch[1])  # mean reduction required\n",
    "\n",
    "    def train_regularization(self, params):\n",
    "        return 0.01 * torch.square(params.norm())\n",
    "\n",
    "    # training loss by default taken to be \n",
    "    # train_loss_on_outputs + train_regularization\n",
    "\n",
    "    def test_loss(self, model, params, batch):\n",
    "        return F.cross_entropy(model(batch[0]), batch[1])  # no regularization in test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 32])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch = next(iter(train_loader)).to(device)\n",
    "train_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (token_embeddings): Embedding(99, 128)\n",
       "  (position_embeddings): Embedding(5, 128)\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x Block(\n",
       "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_influence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutogradInfluenceModule\n\u001b[0;32m----> 3\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mAutogradInfluenceModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMyObjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# influence scores of training points 1, 2, and 3 on test point 0\u001b[39;00m\n\u001b[1;32m     13\u001b[0m scores \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39minfluences([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/dataval/torch-influence/torch_influence/modules.py:61\u001b[0m, in \u001b[0;36mAutogradInfluenceModule.__init__\u001b[0;34m(self, model, objective, train_loader, test_loader, device, damp, check_eigvals)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdamp \u001b[38;5;241m=\u001b[39m damp\n\u001b[1;32m     60\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_make_functional()\n\u001b[0;32m---> 61\u001b[0m flat_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flatten_params_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m d \u001b[38;5;241m=\u001b[39m flat_params\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     64\u001b[0m hess \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/dataval/torch-influence/torch_influence/base.py:283\u001b[0m, in \u001b[0;36mBaseInfluenceModule._flatten_params_like\u001b[0;34m(self, params_like)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params_like:\n\u001b[1;32m    282\u001b[0m     vec\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "from torch_influence import AutogradInfluenceModule\n",
    "   \n",
    "module = AutogradInfluenceModule(\n",
    "    model=model,\n",
    "    objective=MyObjective(),  \n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    damp=0.001\n",
    ")\n",
    "\n",
    "# influence scores of training points 1, 2, and 3 on test point 0\n",
    "scores = module.influences([1, 2, 3], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
